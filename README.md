Safefi - DeFi Risk Assessment Platform

## Overview
Safefi is a professional DeFi risk assessment platform that provides real-time monitoring, ML-powered risk scoring, and institutional-grade analytics.

## âœ¨ NEW: RAG-Powered LLM Assistant ðŸ¤–

**Ask questions about your protocols using natural language!**

```bash
# Example: "What are the high-risk protocols?"
curl -X POST http://YOUR_SERVER:8000/api/v1/llm/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the high-risk protocols?"}'
```

**Features:**
- ðŸ†“ **100% Free** - Uses Ollama (TinyLlama, Mistral, Llama 3)
- ðŸ” **RAG-Powered** - Retrieves context from your database
- ðŸš€ **Streaming** - Real-time token-by-token responses
- â˜ï¸ **Cloud Ready** - Deploy to GCP free tier
- ðŸ“Š **Context-Aware** - Answers based on real risk scores & metrics

**ðŸŽ¯ Recommended Workflow:**

1. **Test Locally First** (30 min) â†’ `QUICK_LOCAL_TEST.md` or `LOCAL_TESTING_GUIDE.md`
2. **Deploy to Production** (2 hours) â†’ `START_HERE.md`

```bash
# Quick local test (if you have PostgreSQL & Node.js):
cd backend && python -m uvicorn app.main:app --reload
cd frontend && npm run dev
# Open: http://localhost:5173

# Then deploy to GCP + Vercel (see START_HERE.md)
```

ðŸ“š **Documentation:**

**Getting Started:**
- â­ **START HERE**: `START_HERE.md` - Production deployment guide
- ðŸ§ª **Test Locally First**: `LOCAL_TESTING_GUIDE.md` - Run locally before deploying
- âš¡ **Quick Local Test**: `QUICK_LOCAL_TEST.md` - 5-minute local verification
- ðŸ”„ **Complete Workflow**: `TESTING_WORKFLOW.md` - Local â†’ Production flow

**Detailed Guides:**
- âœ… **Checklist**: `LLM_SETUP_CHECKLIST.md` - Track your progress
- ðŸ“– **Backend Details**: `GCP_TINYLLAMA_SETUP.md` - GCP setup instructions
- ðŸŽ¨ **Frontend Details**: `FRONTEND_DEPLOYMENT.md` - Vercel deployment
- ðŸ“ **API Examples**: `markdowns/RAG_API_EXAMPLES.md` - Code samples
- ðŸ”§ **Advanced**: `markdowns/RAG_LLM_INTEGRATION.md` - Deep dive  

---

## Tech Stack
- Backend: FastAPI, SQLAlchemy, PostgreSQL, MLflow
- Frontend: React 18, TypeScript, Material-UI (MUI), React Query
- ML Pipeline: scikit-learn, pandas, numpy, MLflow
- **LLM/RAG: Ollama, LangChain, FAISS, sentence-transformers**
- Deployment: AWS Lambda, ECS, RDS, Amplify
- Data Sources: CoinGecko, DeFiLlama

Monorepo Structure
```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ risk.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_scoring.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_providers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ coingecko_client.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ defillama_client.py
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”‚   â””>> training/
â”‚   â”‚   â”‚       â””â”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ alembic/
â”‚   â”‚   â”œâ”€â”€ env.py
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.ts
â”‚   â”‚   â”‚   â””â”€â”€ risk.ts
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Layout.tsx
â”‚   â”‚   â”‚   â””â”€â”€ RiskScoreCard.tsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Protocol.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useRiskScore.ts
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â””â”€â”€ vite-env.d.ts
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”‚   â”œâ”€â”€ features.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ tracking_uri.README
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ aws/
â”‚   â”‚   â”œâ”€â”€ lambda/
â”‚   â”‚   â”‚   â””â”€â”€ placeholder.md
â”‚   â”‚   â”œâ”€â”€ ecs/
â”‚   â”‚   â”‚   â””â”€â”€ placeholder.md
â”‚   â”‚   â”œâ”€â”€ rds/
â”‚   â”‚   â”‚   â””â”€â”€ placeholder.md
â”‚   â”‚   â””â”€â”€ amplify/
â”‚   â”‚       â””â”€â”€ placeholder.md
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .gitignore
```

Getting Started (Dev)
1. Install Docker and Docker Compose
2. Copy `.env.example` to `.env`
3. Start services: `docker compose up -d`
4. Backend: uvicorn at `http://localhost:8000` (once implemented)
5. Frontend: Vite dev server at `http://localhost:5173`

License
Proprietary â€“ All rights reserved.



